{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f813558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import importlib\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import pathlib\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from models.network import AutoEncoder\n",
    "\n",
    "from data.data import ImNetImageSamples, ImNetSamples\n",
    "from torch.multiprocessing import Pool, Process, set_start_method\n",
    "\n",
    "from evaluation.eval_utils import sample_points_polygon_vox64_njit\n",
    "from utils.other_utils import write_ply_point_normal\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db63f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = './../pretrain/class_pretrain/phase_2_model/config.py' \n",
    "data_path = './../data/all_vox256_img_with_classes/all_vox256_img_test.hdf5' \n",
    "input_type = 'voxels' \n",
    "obj_txt_file = './../data/all_vox256_img_with_classes/all_vox256_img_test.txt'\n",
    "network_path = './../pretrain/class_pretrain/phase_2_model/model_epoch_2_310.pth'\n",
    "save_folder = './test_eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1126fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = importlib.util.spec_from_file_location('*', config_path)\n",
    "config = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(config)\n",
    "\n",
    "## dataload\n",
    "### create dataset\n",
    "if input_type == 'image':\n",
    "    samples = ImNetImageSamples(\n",
    "        data_path=args.data_path, \n",
    "        label_txt_path=args.obj_txt_file,\n",
    "        image_idx=23, # Last image, stick to BSP-Net calc\n",
    "        use_depth=hasattr(config, 'use_depth') and config.use_depth,\n",
    "        image_preferred_color_space=config.image_preferred_color_space if hasattr(config, 'image_preferred_color_space') else 1\n",
    "    )\n",
    "elif input_type == 'voxels':\n",
    "    # TODO: In some cases sample_voxel_size could have different size, add to args - not now cause not needed and dont used\n",
    "    samples = ImNetSamples(data_path=data_path, sample_voxel_size=64, label_txt_path=obj_txt_file)\n",
    "else:\n",
    "    raise Exception(f'Unknown input type {input_type}. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b29166c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02691156/d18f2aeae4146464bd46d022fd7d80aa'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.obj_paths[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17bcbf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading index\n",
    "sample_interval = 1\n",
    "resolution = 64\n",
    "max_batch = 20000 if input_type == 'image' else 100000\n",
    "thershold = 0.01\n",
    "with_surface_point = True # TODO: Is it needed here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8961c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_data(samples, i, num_input_data_aggregation, aggregate_embedding, view_use_indx_list):\n",
    "    if aggregate_embedding:\n",
    "        if num_input_data_aggregation is not None and num_input_data_aggregation == -1 and view_use_indx_list is None:\n",
    "            indx_view_iterator = range(samples.view_num)\n",
    "        elif view_use_indx_list is not None and len(view_use_indx_list) > 0:\n",
    "            indx_view_iterator = view_use_indx_list\n",
    "        else:\n",
    "            return [samples[i][0][0] for _ in range(num_input_data_aggregation)]\n",
    "        gathered_data_list = []\n",
    "        for indx_view in indx_view_iterator:\n",
    "            samples.image_idx = int(indx_view)\n",
    "            gathered_data_list.append(\n",
    "                samples[i][0][0]\n",
    "            )\n",
    "        # Can be set to None, we dont care here about value 23 \n",
    "        samples.image_idx = None\n",
    "        return gathered_data_list\n",
    "\n",
    "    return samples[i][0][0]\n",
    "generate_args = [\n",
    "    (\n",
    "        get_input_data(samples, i, -1, False, None), \n",
    "        os.path.join(save_folder, samples.obj_paths[i]), \n",
    "        resolution, max_batch, (-0.5, 0.5), \n",
    "        thershold, with_surface_point\n",
    "    ) \n",
    "    for i in range(10) if i % sample_interval == 0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22b119d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): CNN3D(\n",
       "    (conv_1): Conv3d(1, 48, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (conv_2): Conv3d(48, 96, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (conv_3): Conv3d(96, 192, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (conv_4): Conv3d(192, 384, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (conv_5): Conv3d(384, 384, kernel_size=(4, 4, 4), stride=(1, 1, 1))\n",
       "  )\n",
       "  (decoder): FlowDecoder(\n",
       "    (ode_layers): ModuleList(\n",
       "      (0): ODEfunc(\n",
       "        (ode_net): ODE_ResNet(\n",
       "          (context_linear): Linear(in_features=129, out_features=256, bias=True)\n",
       "          (coordinate_linear): Linear(in_features=3, out_features=256, bias=True)\n",
       "          (last_linear): Linear(in_features=256, out_features=3, bias=True)\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation): Softplus(beta=1, threshold=20)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Linear(in_features=3, out_features=1, bias=True)\n",
       "    (bsp_field): BSPDecoder(\n",
       "      (plane_encoder): PlaneEncoder(\n",
       "        (linear_1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (linear_2): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (linear_3): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (linear_4): Linear(in_features=1024, out_features=16384, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (recognition_decoder): RecognitionDecoder(\n",
       "      (linear_1): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (linear_2): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (linear_3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (linear_4): Linear(in_features=512, out_features=13, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_id = 3\n",
    "torch.cuda.set_device(device_id)\n",
    "spec = importlib.util.spec_from_file_location('*', config_path)\n",
    "config = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(config)\n",
    "\n",
    "network_state_dict = torch.load(network_path)\n",
    "network_state_dict, is_old_style_weights = AutoEncoder.process_state_dict(network_state_dict, type = 1)\n",
    "if is_old_style_weights:\n",
    "    config = AutoEncoder.fix_old_weights_config(config)\n",
    "\n",
    "network = AutoEncoder(config=config).cuda(device_id)\n",
    "network.load_state_dict(network_state_dict)\n",
    "network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60d81f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./test_eval/02691156/d18f2aeae4146464bd46d022fd7d80aa/obj.ply'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indx = 1\n",
    "\n",
    "input_data, store_file_folder_path, resolution, max_batch, space_range, thershold, with_surface_point = generate_args[indx]\n",
    "store_file_path = os.path.join(store_file_folder_path, 'obj.ply')\n",
    "store_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9929b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.from_numpy(input_data[0] if isinstance(input_data, list) else input_data).float().cuda(device_id)\n",
    "result = network.save_bsp_deform(\n",
    "    inputs=input_data, file_path=store_file_path, resolution=resolution, max_batch=max_batch,\n",
    "    space_range=space_range, thershold_1=thershold, embedding=None,\n",
    "    return_voxel_and_values=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12420a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86ca7cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ply_utils import read_ply_point\n",
    "from evaluation.eval import calculate_cd, calculate_normal_consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b967bf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23991, 3), (1258, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices_pd = read_ply_point(store_file_path.replace('obj.ply', 'obj_deformed.ply'))\n",
    "vertices_gt = samples.data_points[indx][samples.data_values[indx][:, 0] > 1e-4]\n",
    "vertices_pd.shape, vertices_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f68ac15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013360625962377526"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_calc = calculate_cd(vertices_pd, vertices_gt)\n",
    "cd_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c05406c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(config, 'sample_class') and config.sample_class:\n",
    "    (vertices, polygons, vertices_deformed, polygons_deformed, \n",
    "        embedding, vertices_convex, bsp_convex_list, \n",
    "        predicted_class, convex_predictions_sum, point_value_prediction) = result\n",
    "    np.save(os.path.join(store_file_folder_path, 'predicted_class_logits.npy'), predicted_class)\n",
    "else:\n",
    "    (vertices, polygons, vertices_deformed, polygons_deformed, \n",
    "        embedding, vertices_convex, bsp_convex_list, \n",
    "        convex_predictions_sum, point_value_prediction) = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "423de7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1425, 3), (1425, 3))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices.shape, vertices_deformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9fe1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
